{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6dbf16-9647-4c2e-b56d-aa46b8f07575",
   "metadata": {},
   "source": [
    "## Checking PyTorch and CUDA Availability\n",
    "\n",
    "In this code cell, we import the PyTorch library and print out information about the availability of CUDA, the CUDA version, and the PyTorch version. This is useful for verifying that PyTorch is correctly installed and that it can utilize the GPU for computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cc3408-19a9-478a-bf26-95366279432a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCUDA Available:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.is_available()) \n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCUDA Version:\u001b[39m\u001b[33m\"\u001b[39m, torch.version.cuda)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available()) \n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748a4c5-3471-47da-a629-b82fd1ac541a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading YOLOv5 Model\n",
    "\n",
    "In this code cell, we load the YOLOv5 model from a local directory using PyTorch's hub module. After loading the model, a confirmation message is printed to indicate that the YOLOv5 model has been successfully loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82d40c-2db5-4ccd-a187-21664413d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/anuragdineshrokade/Documents/YOLO-Object-Detection-and-Classification-for-ADAS/yolov5/yolov5/hubconf.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolov5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolov5n\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocal\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYOLOv5 model loaded successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/hub.py:652\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    643\u001b[39m     repo_or_dir = _get_cache_or_reload(\n\u001b[32m    644\u001b[39m         repo_or_dir,\n\u001b[32m    645\u001b[39m         force_reload,\n\u001b[32m   (...)\u001b[39m\u001b[32m    649\u001b[39m         skip_validation=skip_validation,\n\u001b[32m    650\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m model = \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/hub.py:682\u001b[39m, in \u001b[36m_load_local\u001b[39m\u001b[34m(hubconf_dir, model, *args, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _add_to_sys_path(hubconf_dir):\n\u001b[32m    681\u001b[39m     hubconf_path = os.path.join(hubconf_dir, MODULE_HUBCONF)\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     hub_module = \u001b[43m_import_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODULE_HUBCONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhubconf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    684\u001b[39m     entry = _load_entry_from_hubconf(hub_module, model)\n\u001b[32m    685\u001b[39m     model = entry(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/hub.py:115\u001b[39m, in \u001b[36m_import_module\u001b[39m\u001b[34m(name, path)\u001b[39m\n\u001b[32m    113\u001b[39m module = importlib.util.module_from_spec(spec)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec.loader, Loader)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:758\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexec_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module):\n\u001b[32m    757\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the module.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     code = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    760\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    761\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:895\u001b[39m, in \u001b[36mSourceLoader.get_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n\u001b[32m    891\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _compile_bytecode(bytes_data, name=fullname,\n\u001b[32m    892\u001b[39m                                          bytecode_path=bytecode_path,\n\u001b[32m    893\u001b[39m                                          source_path=source_path)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     source_bytes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m code_object = \u001b[38;5;28mself\u001b[39m.source_to_code(source_bytes, source_path)\n\u001b[32m    897\u001b[39m _bootstrap._verbose_message(\u001b[33m'\u001b[39m\u001b[33mcode object from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m, source_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:953\u001b[39m, in \u001b[36mFileLoader.get_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the data from path as raw bytes.\"\"\"\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, (SourceLoader, ExtensionFileLoader)):\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_code\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m    954\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m file.read()\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/anuragdineshrokade/Documents/YOLO-Object-Detection-and-Classification-for-ADAS/yolov5/yolov5/hubconf.py'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "YOLOV5_REPO = PROJECT_ROOT / \"yolov5_src\"\n",
    "model = torch.hub.load(str(YOLOV5_REPO), 'yolov5n', source='local')\n",
    "print(\"YOLOv5 model loaded successfully from\", YOLOV5_REPO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb63c6-9c1c-48e9-ae50-6aa025e5f027",
   "metadata": {},
   "source": [
    "## Checking GPU Availability and Details\n",
    "\n",
    "This cell checks the availability of CUDA and prints the number of GPUs available. For each available GPU, it also prints its name, helping to identify the GPUs accessible for running PyTorch operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12feeda-fc37-4e2f-b228-f13e27f58e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee4806-b5e7-490a-87d0-0aabf8d52093",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the YOLOv5 Model\n",
    "\n",
    "This cell runs the training script for the YOLOv5 model. Ensure the `data.yaml` file is correctly placed in the `yolov5` directory or provide the correct path to it. The training is configured with an image size of 640, batch size of 16, and runs for 10 epochs. The training weights are initialized with `yolov5n.pt`, and the process runs on device 0 (usually the first GPU). The results are saved in the `runs/train` directory under the name `exp_model-n_img-640`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6005ed-3be6-4ea8-b94a-3b3aa01ca082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "YOLOV5_REPO = PROJECT_ROOT / \"yolov5_src\"\n",
    "DATA_YAML = PROJECT_ROOT / \"dataset\" / \"data.yaml\"\n",
    "WEIGHTS = YOLOV5_REPO / \"yolov5n.pt\"\n",
    "PROJECT_DIR = NOTEBOOK_DIR / \"runs\"\n",
    "RUN_NAME = \"exp_dummy\"\n",
    "\n",
    "!python {YOLOV5_REPO / 'train.py'} --img 640 --batch 4 --epochs 1 --data {DATA_YAML} --weights {WEIGHTS} --device cpu --project {PROJECT_DIR / 'train'} --name {RUN_NAME} --exist-ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6cd8-2946-498c-be90-99fb615edcd5",
   "metadata": {},
   "source": [
    "## Object Detection and Visualization with YOLOv5\n",
    "\n",
    "This cell performs object detection on a set of test images using a custom-trained YOLOv5 model and visualizes the results with bounding boxes and labels.\n",
    "\n",
    "1. **Load the YOLOv5 Model**: The model is loaded from the specified path where the custom weights are stored.\n",
    "2. **Define a Function to Draw Bounding Boxes and Labels**: This function draws bounding boxes and labels on the detected objects in the image.\n",
    "3. **Specify Paths**: Set the paths for the directory containing the test images and the directory where the processed images will be saved.\n",
    "4. **Process Test Images**: \n",
    "    - List all image files in the test images directory.\n",
    "    - For each image, apply the YOLOv5 model to detect objects.\n",
    "    - Draw bounding boxes and labels on the detected objects.\n",
    "    - Save the processed images to the output directory.\n",
    "    - Optionally, display the processed images.\n",
    "\n",
    "The bounding boxes and labels are drawn using OpenCV, and the processed images are saved to the specified output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac716e82-6ca0-4b47-97c4-f79c84f7d56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "YOLOV5_REPO = PROJECT_ROOT / \"yolov5_src\"\n",
    "RUN_DIR = NOTEBOOK_DIR / \"runs\" / \"train\" / \"exp_dummy\" / \"weights\"\n",
    "WEIGHTS_PATH = (RUN_DIR / \"best.pt\") if (RUN_DIR / \"best.pt\").exists() else (RUN_DIR / \"last.pt\")\n",
    "TEST_IMAGES_DIR = PROJECT_ROOT / \"dataset\" / \"images\" / \"val\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output_images_test_set\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "if not WEIGHTS_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Expected weights not found in {RUN_DIR}\")\n",
    "\n",
    "if not TEST_IMAGES_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Test images directory missing: {TEST_IMAGES_DIR}\")\n",
    "\n",
    "model = torch.hub.load(str(YOLOV5_REPO), 'custom', path=str(WEIGHTS_PATH), source='local', force_reload=True)\n",
    "\n",
    "\n",
    "def draw_boxes(image, results):\n",
    "    for pred in results.pred[0].detach().cpu().numpy():\n",
    "        x1, y1, x2, y2, conf, cls = pred\n",
    "        label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(image, (int(x1), int(y1) - 20), (int(x1) + w, int(y1)), (0, 255, 0), -1)\n",
    "        cv2.putText(image, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(TEST_IMAGES_DIR) if f.lower().endswith(('.jpg', '.png'))])\n",
    "print(f\"Processing {len(image_files)} images from {TEST_IMAGES_DIR}\")\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = TEST_IMAGES_DIR / image_file\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        print(f\"Skipping unreadable file: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    results = model(image)\n",
    "    draw_boxes(image, results)\n",
    "\n",
    "    output_image_path = OUTPUT_DIR / image_file\n",
    "    cv2.imwrite(str(output_image_path), image)\n",
    "    print(f\"Saved detections to {output_image_path}\")\n",
    "\n",
    "print(f\"All processed images saved to {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429156-d8fe-448d-a23a-72add1058c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
